import os
import json
import requests
from bs4 import BeautifulSoup
from fpdf import FPDF
import tweepy
from datetime import datetime, timedelta
import hashlib

HISTORY_FILE = "posted_articles.json"
HASHTAG_FILE = "hashtags.json"
ACCOUNT_FILE = "accounts.json"
SUMMARY_FILE = "summaries.json"

def fetch_latest_ai_articles():
    """Firecrawl MCP ile geliÅŸmiÅŸ haber Ã§ekme - Sadece son 4 makale"""
    try:
        # Ã–nce mevcut yayÄ±nlanan makaleleri yÃ¼kle
        posted_articles = load_json(HISTORY_FILE)
        posted_urls = [article.get('url', '') for article in posted_articles]
        posted_hashes = [article.get('hash', '') for article in posted_articles]
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        html = requests.get("https://techcrunch.com/category/artificial-intelligence/", headers=headers).text
        soup = BeautifulSoup(html, "html.parser")
        article_links = soup.select("a.loop-card__title-link")[:4]  # Sadece son 4 makale
        
        print(f"ğŸ” TechCrunch AI kategorisinden son {len(article_links)} makale kontrol ediliyor...")
        
        articles_data = []
        for link_tag in article_links:
            title = link_tag.text.strip()
            url = link_tag['href']
            
            # Makale hash'i oluÅŸtur (baÅŸlÄ±k bazlÄ±)
            article_hash = hashlib.md5(title.encode()).hexdigest()
            
            # Tekrar kontrolÃ¼ - URL ve hash bazlÄ±
            is_already_posted = url in posted_urls or article_hash in posted_hashes
            
            if is_already_posted:
                print(f"âœ… Makale zaten paylaÅŸÄ±lmÄ±ÅŸ, atlanÄ±yor: {title[:50]}...")
                continue
            
            # Makale iÃ§eriÄŸini geliÅŸmiÅŸ ÅŸekilde Ã§ek
            content = fetch_article_content_advanced(url, headers)
            
            if content and len(content) > 100:  # Minimum iÃ§erik kontrolÃ¼
                articles_data.append({
                    "title": title, 
                    "url": url, 
                    "content": content,
                    "hash": article_hash,
                    "fetch_date": datetime.now().isoformat(),
                    "is_new": True,  # Yeni makale iÅŸareti
                    "already_posted": False
                })
                print(f"ğŸ†• Yeni makale bulundu: {title[:50]}...")
            else:
                print(f"âš ï¸ Ä°Ã§erik yetersiz, atlanÄ±yor: {title[:50]}...")
        
        print(f"ğŸ“Š Toplam {len(articles_data)} yeni makale bulundu (son 4 makale kontrol edildi)")
        return articles_data
        
    except Exception as e:
        print(f"Haber Ã§ekme hatasÄ±: {e}")
        return []

def fetch_article_content_advanced(url, headers):
    """GeliÅŸmiÅŸ makale iÃ§eriÄŸi Ã§ekme - Firecrawl benzeri"""
    try:
        article_html = requests.get(url, headers=headers, timeout=10).text
        article_soup = BeautifulSoup(article_html, "html.parser")
        
        # Ã‡oklu selector deneme - daha kapsamlÄ± iÃ§erik Ã§ekme
        content_selectors = [
            "div.article-content p",
            "div.entry-content p", 
            "div.post-content p",
            "article p",
            "div.content p",
            ".article-body p"
        ]
        
        content = ""
        for selector in content_selectors:
            paragraphs = article_soup.select(selector)
            if paragraphs:
                content = "\n".join([p.text.strip() for p in paragraphs if p.text.strip()])
                if len(content) > 200:  # Yeterli iÃ§erik bulundu
                    break
        
        # EÄŸer hala iÃ§erik bulunamadÄ±ysa, tÃ¼m p etiketlerini dene
        if not content:
            all_paragraphs = article_soup.find_all('p')
            content = "\n".join([p.text.strip() for p in all_paragraphs if len(p.text.strip()) > 50])
        
        return content[:2000]  # Ä°Ã§eriÄŸi sÄ±nÄ±rla
        
    except Exception as e:
        print(f"Makale iÃ§eriÄŸi Ã§ekme hatasÄ± ({url}): {e}")
        return ""

def load_json(path):
    return json.load(open(path, 'r', encoding='utf-8')) if os.path.exists(path) else []

def save_json(path, data):
    with open(path, "w", encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def summarize_article(article_content, api_key):
    """LLM ile geliÅŸmiÅŸ makale Ã¶zetleme"""
    prompt = f"""AÅŸaÄŸÄ±daki AI/teknoloji haberini TÃ¼rkÃ§e olarak Ã¶zetle. Ã–zet tweet formatÄ±nda, ilgi Ã§ekici ve bilgilendirici olsun:

Haber Ä°Ã§eriÄŸi:
{article_content[:1500]}

LÃ¼tfen:
- Maksimum 200 karakter
- Ana konuyu vurgula
- Teknik detaylarÄ± basitleÅŸtir
- Ä°lgi Ã§ekici bir dil kullan

Ã–zet:"""
    return openrouter_call(prompt, api_key, max_tokens=100)

def score_article(article_content, api_key):
    prompt = f"""Bu AI/teknoloji haberinin Ã¶nemini 1-10 arasÄ±nda deÄŸerlendir (sadece sayÄ±):

{article_content[:800]}

DeÄŸerlendirme kriterleri:
- Yenilik derecesi
- SektÃ¶rel etki
- GeliÅŸtiriciler iÃ§in Ã¶nem
- Genel ilgi

Puan:"""
    result = openrouter_call(prompt, api_key, max_tokens=5)
    try:
        return int(result.strip().split()[0])
    except:
        return 5

def categorize_article(article_content, api_key):
    prompt = f"""Bu haberin hedef kitlesini belirle:

{article_content[:500]}

SeÃ§enekler: Developer, Investor, General
Cevap:"""
    return openrouter_call(prompt, api_key, max_tokens=10).strip()

def openrouter_call(prompt, api_key, max_tokens=100):
    if not api_key:
        print("API anahtarÄ± bulunamadÄ±")
        return "API anahtarÄ± eksik"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "HTTP-Referer": "https://yourdomain.com",
        "X-Title": "VibeAI",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "deepseek/deepseek-chat-v3-0324:free",  # Daha gÃ¼venilir model
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": max_tokens
    }
    
    try:
        print(f"[DEBUG] API Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±yor... Model: {payload['model']}")
        r = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=headers, json=payload, timeout=30)
        
        print(f"[DEBUG] API YanÄ±t Kodu: {r.status_code}")
        
        if r.status_code != 200:
            print(f"API HatasÄ±: Durum Kodu {r.status_code}, YanÄ±t: {r.text}")
            return "API hatasÄ±"

        response_json = r.json()
        print(f"[DEBUG] API YanÄ±tÄ± alÄ±ndÄ±: {len(str(response_json))} karakter")
        
        if "choices" not in response_json or not response_json["choices"]:
            print(f"API YanÄ±tÄ±nda 'choices' anahtarÄ± bulunamadÄ±. YanÄ±t: {response_json}")
            return "YanÄ±t formatÄ± hatalÄ±"
        
        content = response_json["choices"][0]["message"]["content"]
        print(f"[DEBUG] Ä°Ã§erik alÄ±ndÄ±: {len(content)} karakter")
        return content.strip()
        
    except Exception as e:
        print(f"OpenRouter API Ã§aÄŸrÄ± hatasÄ±: {e}")
        return "BaÄŸlantÄ± hatasÄ±"

def generate_ai_tweet_with_content(article_data, api_key):
    """Makale iÃ§eriÄŸini okuyarak geliÅŸmiÅŸ tweet oluÅŸturma"""
    title = article_data.get("title", "")
    content = article_data.get("content", "")
    url = article_data.get("url", "")
    
    # EÄŸer iÃ§erik yoksa baÅŸlÄ±k kullan
    if not content:
        content = title
    
    prompt = f"""AÅŸaÄŸÄ±daki AI/teknoloji haberinden etkileyici bir tweet oluÅŸtur:

BaÅŸlÄ±k: {title}
Ä°Ã§erik: {content[:1200]}

Tweet Gereksinimleri:
- Maksimum 200 karakter (URL iÃ§in yer bÄ±rak)
- TÃ¼rkÃ§e olsun
- Ä°lgi Ã§ekici emoji kullan
- Relevant hashtag'ler ekle (#AI #Teknoloji #YapayZeka)
- Ana konuyu vurgula
- Merak uyandÄ±rÄ±cÄ± olsun
- Sadece tweet metnini dÃ¶ndÃ¼r, baÅŸka aÃ§Ä±klama yapma

Tweet:"""
    
    try:
        generated_tweet = openrouter_call(prompt, api_key, max_tokens=150)
        
        # API hatasÄ± kontrolÃ¼
        if not generated_tweet or generated_tweet in ["Ã–zet oluÅŸturulamadÄ±", "API hatasÄ±", "BaÄŸlantÄ± hatasÄ±", "API anahtarÄ± eksik", "YanÄ±t formatÄ± hatalÄ±"]:
            # Fallback tweet oluÅŸtur
            print(f"[FALLBACK] API hatasÄ±, fallback tweet oluÅŸturuluyor...")
            generated_tweet = create_fallback_tweet(title, content)
        elif len(generated_tweet.strip()) < 10:
            # Ã‡ok kÄ±sa yanÄ±t
            print(f"[FALLBACK] Ã‡ok kÄ±sa yanÄ±t, fallback tweet oluÅŸturuluyor...")
            generated_tweet = create_fallback_tweet(title, content)
        
        # URL'yi tweet'e ekle
        if url and url != "#":
            # Tweet uzunluÄŸunu kontrol et
            max_tweet_length = 250  # URL iÃ§in yer bÄ±rak
            if len(generated_tweet) > max_tweet_length:
                generated_tweet = generated_tweet[:max_tweet_length-3] + "..."
            
            final_tweet = f"{generated_tweet}\n\nğŸ”— {url}"
        else:
            final_tweet = generated_tweet
            
        return final_tweet
        
    except Exception as e:
        print(f"Tweet oluÅŸturma hatasÄ±: {e}")
        # Hata durumunda fallback tweet oluÅŸtur
        fallback_tweet = create_fallback_tweet(title, content)
        if url and url != "#":
            fallback_tweet += f"\n\nğŸ”— {url}"
        return fallback_tweet

def create_fallback_tweet(title, content):
    """API hatasÄ± durumunda fallback tweet oluÅŸtur"""
    try:
        # BaÅŸlÄ±ÄŸÄ± temizle ve kÄ±salt
        clean_title = title.strip()
        
        # Ä°Ã§erikten anahtar kelimeler ve Ã¶nemli bilgiler Ã§Ä±kar
        keywords = []
        ai_keywords = ["AI", "yapay zeka", "artificial intelligence", "machine learning", "deep learning", "neural", "GPT", "LLM", "model", "algorithm", "ChatGPT", "OpenAI", "Google", "Microsoft", "Meta", "Anthropic"]
        tech_keywords = ["teknoloji", "technology", "software", "platform", "startup", "company", "billion", "million", "funding", "investment", "acquisition", "launch", "release"]
        
        content_lower = content.lower()
        title_lower = title.lower()
        combined_text = f"{title_lower} {content_lower}"
        
        # AI anahtar kelimeleri kontrol et
        for keyword in ai_keywords:
            if keyword.lower() in combined_text:
                keywords.append("AI")
                break
        
        # Teknoloji anahtar kelimeleri kontrol et
        for keyword in tech_keywords:
            if keyword.lower() in combined_text:
                keywords.append("Teknoloji")
                break
        
        # SayÄ±sal bilgileri Ã§Ä±kar (milyar, milyon, yÃ¼zde vb.)
        import re
        numbers = re.findall(r'\$?(\d+(?:\.\d+)?)\s*(billion|million|milyar|milyon|%|percent)', combined_text, re.IGNORECASE)
        
        # Åirket isimlerini tespit et
        companies = []
        company_names = ["OpenAI", "Google", "Microsoft", "Meta", "Apple", "Amazon", "Tesla", "Nvidia", "Anthropic", "Perplexity", "Cursor", "DeviantArt"]
        for company in company_names:
            if company.lower() in combined_text:
                companies.append(company)
        
        # Emoji seÃ§ (konuya gÃ¶re)
        if "funding" in combined_text or "investment" in combined_text or "billion" in combined_text:
            emoji = "ğŸ’°"
        elif "launch" in combined_text or "release" in combined_text or "unveil" in combined_text:
            emoji = "ğŸš€"
        elif "model" in combined_text or "AI" in combined_text:
            emoji = "ğŸ¤–"
        elif "research" in combined_text or "development" in combined_text:
            emoji = "ğŸ”¬"
        elif "security" in combined_text or "government" in combined_text:
            emoji = "ğŸ”’"
        else:
            import random
            emojis = ["ğŸ¤–", "ğŸ’»", "ğŸš€", "âš¡", "ğŸ”¥", "ğŸ’¡", "ğŸŒŸ", "ğŸ“±", "ğŸ¯", "ğŸ’°"]
            emoji = random.choice(emojis)
        
        # Tweet iÃ§eriÄŸi oluÅŸtur
        tweet_parts = []
        
        # BaÅŸlÄ±k (kÄ±saltÄ±lmÄ±ÅŸ)
        if len(clean_title) > 120:
            clean_title = clean_title[:117] + "..."
        
        # Ana tweet metni
        main_text = f"{emoji} {clean_title}"
        
        # Ek bilgiler ekle
        if numbers:
            # En bÃ¼yÃ¼k sayÄ±yÄ± al
            largest_num = max(numbers, key=lambda x: float(x[0]))
            if largest_num[1].lower() in ['billion', 'milyar']:
                main_text += f" - {largest_num[0]} milyar dolarlÄ±k geliÅŸme!"
            elif largest_num[1].lower() in ['million', 'milyon']:
                main_text += f" - {largest_num[0]} milyon kullanÄ±cÄ± etkisi!"
        
        # Åirket bilgisi ekle
        if companies:
            main_company = companies[0]
            if len(main_text) < 180:
                main_text += f" {main_company}'dan Ã¶nemli adÄ±m!"
        
        # Ä°Ã§erikten Ã¶nemli cÃ¼mle Ã§Ä±kar
        if content and len(content) > 50:
            sentences = content.split('.')
            for sentence in sentences[:3]:  # Ä°lk 3 cÃ¼mleyi kontrol et
                sentence = sentence.strip()
                if len(sentence) > 30 and len(sentence) < 100:
                    # Ã–nemli kelimeler iÃ§eriyorsa ekle
                    important_words = ["announced", "launched", "released", "unveiled", "raised", "acquired", "developed"]
                    if any(word in sentence.lower() for word in important_words):
                        if len(main_text) + len(sentence) < 200:
                            main_text += f" {sentence}."
                        break
        
        # Hashtag'ler oluÅŸtur
        hashtags = []
        if keywords:
            hashtags.extend([f"#{k}" for k in keywords])
        
        # Konuya Ã¶zel hashtag'ler ekle
        if "funding" in combined_text or "investment" in combined_text:
            hashtags.append("#YatÄ±rÄ±m")
        if "model" in combined_text:
            hashtags.append("#YapayZeka")
        if "security" in combined_text:
            hashtags.append("#GÃ¼venlik")
        if "browser" in combined_text:
            hashtags.append("#TarayÄ±cÄ±")
        
        # VarsayÄ±lan hashtag'ler
        if not hashtags:
            hashtags = ["#AI", "#Teknoloji", "#YapayZeka"]
        else:
            hashtags.append("#YapayZeka")
        
        # Hashtag'leri sÄ±nÄ±rla (maksimum 4)
        hashtags = hashtags[:4]
        hashtag_text = " ".join(hashtags)
        
        # Final tweet oluÅŸtur
        fallback_tweet = f"{main_text} {hashtag_text}"
        
        # Uzunluk kontrolÃ¼ ve optimizasyon
        if len(fallback_tweet) > 250:
            # Hashtag'leri azalt
            hashtags = hashtags[:2]
            hashtag_text = " ".join(hashtags)
            fallback_tweet = f"{main_text} {hashtag_text}"
            
            if len(fallback_tweet) > 250:
                # Ana metni kÄ±salt
                available_length = 250 - len(hashtag_text) - 5
                main_text = main_text[:available_length] + "..."
                fallback_tweet = f"{main_text} {hashtag_text}"
        
        # Minimum uzunluk kontrolÃ¼
        if len(fallback_tweet) < 50:
            # Ã‡ok kÄ±sa ise ek bilgi ekle
            extra_info = " Bu geliÅŸme teknoloji dÃ¼nyasÄ±nda Ã¶nemli bir adÄ±m!"
            if len(fallback_tweet) + len(extra_info) <= 250:
                fallback_tweet += extra_info
        
        return fallback_tweet
        
    except Exception as e:
        print(f"Fallback tweet oluÅŸturma hatasÄ±: {e}")
        # En basit fallback
        return f"ğŸ¤– {title[:180]}... #AI #Teknoloji #YapayZeka"

def setup_twitter_api():
    """X (Twitter) API kurulumu"""
    try:
        bearer_token = os.getenv("TWITTER_BEARER_TOKEN")
        api_key = os.getenv("TWITTER_API_KEY")
        api_secret = os.getenv("TWITTER_API_SECRET")
        access_token = os.getenv("TWITTER_ACCESS_TOKEN")
        access_token_secret = os.getenv("TWITTER_ACCESS_TOKEN_SECRET")
        
        if not all([bearer_token, api_key, api_secret, access_token, access_token_secret]):
            raise ValueError("Twitter API anahtarlarÄ± eksik. .env dosyasÄ±nÄ± kontrol edin.")
        
        # Twitter API v2 client
        client = tweepy.Client(
            bearer_token=bearer_token,
            consumer_key=api_key,
            consumer_secret=api_secret,
            access_token=access_token,
            access_token_secret=access_token_secret,
            wait_on_rate_limit=True
        )
        
        return client
    except Exception as e:
        print(f"Twitter API kurulum hatasÄ±: {e}")
        return None

def post_tweet(tweet_text):
    """X platformunda tweet paylaÅŸma"""
    try:
        client = setup_twitter_api()
        if not client:
            return {"success": False, "error": "Twitter API kurulumu baÅŸarÄ±sÄ±z"}
        
        # Tweet uzunluk kontrolÃ¼
        if len(tweet_text) > 280:
            tweet_text = tweet_text[:277] + "..."
        
        response = client.create_tweet(text=tweet_text)
        
        if response.data:
            tweet_id = response.data['id']
            return {
                "success": True, 
                "tweet_id": tweet_id,
                "url": f"https://twitter.com/user/status/{tweet_id}"
            }
        else:
            return {"success": False, "error": "Tweet oluÅŸturulamadÄ±"}
            
    except Exception as e:
        return {"success": False, "error": f"Tweet paylaÅŸÄ±m hatasÄ±: {str(e)}"}

def mark_article_as_posted(article_data, tweet_result):
    """Makaleyi paylaÅŸÄ±ldÄ± olarak iÅŸaretle"""
    try:
        posted_articles = load_json(HISTORY_FILE)
        
        posted_article = {
            "title": article_data.get("title", ""),
            "url": article_data.get("url", ""),
            "hash": article_data.get("hash", ""),
            "posted_date": datetime.now().isoformat(),
            "tweet_id": tweet_result.get("tweet_id", ""),
            "tweet_url": tweet_result.get("url", "")
        }
        
        posted_articles.append(posted_article)
        save_json(HISTORY_FILE, posted_articles)
        
        return True
    except Exception as e:
        print(f"Makale kaydetme hatasÄ±: {e}")
        return False

def check_duplicate_articles():
    """Tekrarlanan makaleleri temizle"""
    try:
        posted_articles = load_json(HISTORY_FILE)
        
        # Son 30 gÃ¼nlÃ¼k makaleleri tut
        cutoff_date = datetime.now() - timedelta(days=30)
        
        filtered_articles = []
        seen_hashes = set()
        
        for article in posted_articles:
            try:
                posted_date = datetime.fromisoformat(article.get("posted_date", ""))
                article_hash = article.get("hash", "")
                
                if posted_date > cutoff_date and article_hash not in seen_hashes:
                    filtered_articles.append(article)
                    seen_hashes.add(article_hash)
            except:
                continue
        
        save_json(HISTORY_FILE, filtered_articles)
        return len(posted_articles) - len(filtered_articles)
        
    except Exception as e:
        print(f"Tekrar temizleme hatasÄ±: {e}")
        return 0

def generate_ai_digest(summaries_with_links, api_key):
    """Eski fonksiyon - geriye dÃ¶nÃ¼k uyumluluk iÃ§in"""
    if not summaries_with_links:
        return "Ã–zet bulunamadÄ±"
    
    # Ä°lk makaleyi kullanarak tweet oluÅŸtur
    first_summary = summaries_with_links[0]
    article_data = {
        "title": "AI Digest",
        "content": first_summary.get("summary", ""),
        "url": first_summary.get("url", "")
    }
    
    return generate_ai_tweet_with_content(article_data, api_key)

def create_pdf(summaries, filename="daily_digest.pdf"):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="AI Tweet Digest", ln=True, align='C')
    for s in summaries:
        pdf.multi_cell(0, 10, f"â€¢ {s}")
    pdf.output(filename)
    return filename

def get_posted_articles_summary():
    """PaylaÅŸÄ±lmÄ±ÅŸ makalelerin Ã¶zetini dÃ¶ndÃ¼r"""
    try:
        posted_articles = load_json(HISTORY_FILE)
        
        # Son 7 gÃ¼nlÃ¼k makaleleri al
        cutoff_date = datetime.now() - timedelta(days=7)
        recent_articles = []
        
        for article in posted_articles:
            try:
                posted_date = datetime.fromisoformat(article.get("posted_date", ""))
                if posted_date > cutoff_date:
                    recent_articles.append(article)
            except:
                continue
        
        return {
            "total_posted": len(posted_articles),
            "recent_posted": len(recent_articles),
            "recent_articles": recent_articles[-5:]  # Son 5 makale
        }
        
    except Exception as e:
        print(f"PaylaÅŸÄ±lmÄ±ÅŸ makale Ã¶zeti hatasÄ±: {e}")
        return {"total_posted": 0, "recent_posted": 0, "recent_articles": []}

def reset_all_data():
    """TÃ¼m uygulama verilerini sÄ±fÄ±rla"""
    try:
        files_to_reset = [
            "posted_articles.json",
            "pending_tweets.json", 
            "summaries.json",
            "hashtags.json",
            "accounts.json"
        ]
        
        reset_count = 0
        for file_path in files_to_reset:
            if os.path.exists(file_path):
                save_json(file_path, [])
                reset_count += 1
                print(f"âœ… {file_path} sÄ±fÄ±rlandÄ±")
            else:
                # Dosya yoksa boÅŸ oluÅŸtur
                save_json(file_path, [])
                print(f"ğŸ†• {file_path} oluÅŸturuldu")
        
        return {
            "success": True,
            "message": f"âœ… {reset_count} dosya sÄ±fÄ±rlandÄ±",
            "reset_files": files_to_reset
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ SÄ±fÄ±rlama hatasÄ±: {str(e)}",
            "reset_files": []
        }

def clear_pending_tweets():
    """Sadece bekleyen tweet'leri temizle"""
    try:
        pending_tweets = load_json("pending_tweets.json")
        
        # Sadece posted olanlarÄ± tut, pending olanlarÄ± sil
        posted_tweets = [t for t in pending_tweets if t.get("status") == "posted"]
        
        save_json("pending_tweets.json", posted_tweets)
        
        cleared_count = len(pending_tweets) - len(posted_tweets)
        
        return {
            "success": True,
            "message": f"âœ… {cleared_count} bekleyen tweet temizlendi",
            "cleared_count": cleared_count
        }
        
    except Exception as e:
        return {
            "success": False,
            "message": f"âŒ Temizleme hatasÄ±: {str(e)}",
            "cleared_count": 0
        }

def get_data_statistics():
    """Veri istatistiklerini dÃ¶ndÃ¼r"""
    try:
        stats = {}
        
        # PaylaÅŸÄ±lan makaleler
        posted_articles = load_json("posted_articles.json")
        stats["posted_articles"] = len(posted_articles)
        
        # Bekleyen tweet'ler
        pending_tweets = load_json("pending_tweets.json")
        pending_count = len([t for t in pending_tweets if t.get("status") == "pending"])
        posted_count = len([t for t in pending_tweets if t.get("status") == "posted"])
        stats["pending_tweets"] = pending_count
        stats["posted_tweets_in_pending"] = posted_count
        
        # Ã–zetler
        summaries = load_json("summaries.json")
        stats["summaries"] = len(summaries)
        
        # Hashtag'ler
        hashtags = load_json("hashtags.json")
        stats["hashtags"] = len(hashtags)
        
        # Hesaplar
        accounts = load_json("accounts.json")
        stats["accounts"] = len(accounts)
        
        return stats
        
    except Exception as e:
        print(f"Ä°statistik hatasÄ±: {e}")
        return {
            "posted_articles": 0,
            "pending_tweets": 0,
            "posted_tweets_in_pending": 0,
            "summaries": 0,
            "hashtags": 0,
            "accounts": 0
        }

def load_automation_settings():
    """OtomatikleÅŸtirme ayarlarÄ±nÄ± yÃ¼kle"""
    try:
        settings_data = load_json("automation_settings.json")
        
        # EÄŸer liste ise (eski format), boÅŸ dict dÃ¶ndÃ¼r
        if isinstance(settings_data, list):
            settings = {}
        else:
            settings = settings_data
        
        # VarsayÄ±lan ayarlar
        default_settings = {
            "auto_mode": False,
            "min_score": 5,
            "check_interval_hours": 3,
            "max_articles_per_run": 10,
            "auto_post_enabled": False,
            "require_manual_approval": True,
            "working_hours_only": False,
            "working_hours_start": "09:00",
            "working_hours_end": "18:00",
            "weekend_enabled": True,
            "rate_limit_delay": 2,
            "last_updated": datetime.now().isoformat()
        }
        
        # Eksik ayarlarÄ± varsayÄ±lanlarla doldur
        for key, value in default_settings.items():
            if key not in settings:
                settings[key] = value
        
        return settings
        
    except Exception as e:
        print(f"Ayarlar yÃ¼kleme hatasÄ±: {e}")
        # VarsayÄ±lan ayarlarÄ± dÃ¶ndÃ¼r
        return {
            "auto_mode": False,
            "min_score": 5,
            "check_interval_hours": 3,
            "max_articles_per_run": 10,
            "auto_post_enabled": False,
            "require_manual_approval": True,
            "working_hours_only": False,
            "working_hours_start": "09:00",
            "working_hours_end": "18:00",
            "weekend_enabled": True,
            "rate_limit_delay": 2,
            "last_updated": datetime.now().isoformat()
        }

def save_automation_settings(settings):
    """OtomatikleÅŸtirme ayarlarÄ±nÄ± kaydet"""
    try:
        settings["last_updated"] = datetime.now().isoformat()
        save_json("automation_settings.json", settings)
        return {"success": True, "message": "âœ… Ayarlar baÅŸarÄ±yla kaydedildi"}
    except Exception as e:
        return {"success": False, "message": f"âŒ Ayarlar kaydedilemedi: {e}"}

def get_automation_status():
    """OtomatikleÅŸtirme durumunu kontrol et"""
    try:
        settings = load_automation_settings()
        
        # Ã‡alÄ±ÅŸma saatleri kontrolÃ¼
        if settings.get("working_hours_only", False):
            from datetime import datetime, time
            now = datetime.now()
            start_time = datetime.strptime(settings.get("working_hours_start", "09:00"), "%H:%M").time()
            end_time = datetime.strptime(settings.get("working_hours_end", "18:00"), "%H:%M").time()
            
            current_time = now.time()
            is_working_hours = start_time <= current_time <= end_time
            
            # Hafta sonu kontrolÃ¼
            is_weekend = now.weekday() >= 5  # 5=Cumartesi, 6=Pazar
            weekend_allowed = settings.get("weekend_enabled", True)
            
            if is_weekend and not weekend_allowed:
                return {
                    "active": False,
                    "reason": "Hafta sonu Ã§alÄ±ÅŸma devre dÄ±ÅŸÄ±",
                    "settings": settings
                }
            
            if not is_working_hours:
                return {
                    "active": False,
                    "reason": f"Ã‡alÄ±ÅŸma saatleri dÄ±ÅŸÄ±nda ({start_time}-{end_time})",
                    "settings": settings
                }
        
        return {
            "active": settings.get("auto_mode", False),
            "reason": "Aktif" if settings.get("auto_mode", False) else "Manuel mod",
            "settings": settings
        }
        
    except Exception as e:
        return {
            "active": False,
            "reason": f"Hata: {e}",
            "settings": {}
        }

def update_scheduler_settings():
    """Scheduler ayarlarÄ±nÄ± gÃ¼ncelle (scheduler.py iÃ§in)"""
    try:
        settings = load_automation_settings()
        
        # Scheduler iÃ§in ayarlar dosyasÄ± oluÅŸtur
        scheduler_config = {
            "auto_mode": settings.get("auto_mode", False),
            "min_score": settings.get("min_score", 5),
            "check_interval_hours": settings.get("check_interval_hours", 3),
            "max_articles_per_run": settings.get("max_articles_per_run", 10),
            "auto_post_enabled": settings.get("auto_post_enabled", False),
            "rate_limit_delay": settings.get("rate_limit_delay", 2),
            "last_updated": datetime.now().isoformat()
        }
        
        save_json("scheduler_config.json", scheduler_config)
        return {"success": True, "message": "Scheduler ayarlarÄ± gÃ¼ncellendi"}
        
    except Exception as e:
        return {"success": False, "message": f"Scheduler ayarlarÄ± gÃ¼ncellenemedi: {e}"}

def validate_automation_settings(settings):
    """OtomatikleÅŸtirme ayarlarÄ±nÄ± doÄŸrula"""
    errors = []
    
    # Minimum skor kontrolÃ¼
    min_score = settings.get("min_score", 5)
    if not isinstance(min_score, int) or min_score < 1 or min_score > 10:
        errors.append("Minimum skor 1-10 arasÄ±nda olmalÄ±")
    
    # Kontrol aralÄ±ÄŸÄ± kontrolÃ¼
    interval = settings.get("check_interval_hours", 3)
    if not isinstance(interval, (int, float)) or interval < 0.5 or interval > 24:
        errors.append("Kontrol aralÄ±ÄŸÄ± 0.5-24 saat arasÄ±nda olmalÄ±")
    
    # Maksimum makale sayÄ±sÄ± kontrolÃ¼
    max_articles = settings.get("max_articles_per_run", 10)
    if not isinstance(max_articles, int) or max_articles < 1 or max_articles > 50:
        errors.append("Maksimum makale sayÄ±sÄ± 1-50 arasÄ±nda olmalÄ±")
    
    # Ã‡alÄ±ÅŸma saatleri kontrolÃ¼
    try:
        start_time = settings.get("working_hours_start", "09:00")
        end_time = settings.get("working_hours_end", "18:00")
        datetime.strptime(start_time, "%H:%M")
        datetime.strptime(end_time, "%H:%M")
    except ValueError:
        errors.append("Ã‡alÄ±ÅŸma saatleri HH:MM formatÄ±nda olmalÄ±")
    
    # Rate limit kontrolÃ¼
    rate_delay = settings.get("rate_limit_delay", 2)
    if not isinstance(rate_delay, (int, float)) or rate_delay < 0 or rate_delay > 60:
        errors.append("Rate limit gecikmesi 0-60 saniye arasÄ±nda olmalÄ±")
    
    return errors
